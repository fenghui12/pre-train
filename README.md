# LLM 微调与管理助手 v2.0

这是一个集成了模型训练、管理和推理功能的一站式桌面应用。它提供了一个现代化的图形用户界面 (GUI)，使用户能够轻松地训练自定义 LoRA 模型，管理和转换模型格式，并立即进行聊天测试。

## 主要功能

- **统一的UI体验**: 所有功能都整合在一个采用多标签页设计的现代化界面中，工作流清晰，操作直观。
- **训练功能**:
  - 支持**新 LoRA 训练**和**继续训练现有 LoRA** 两种模式。
  - 自动扫描本地 Hugging Face 缓存，发现可用的基座模型。
- **模型管理**:
  - **合并 LoRA**: 将训练好的 LoRA 适配器与基座模型合并，并一键导入到 Ollama。
  - **转换基座模型**: 支持将任意 Hugging Face 模型（如果本地没有会自动下载）转换为 GGUF 格式并导入 Ollama。
- **集成推理**:
  - 内置聊天界面，可加载任意本地模型（基座或LoRA）进行即时对话测试。
  - 支持上下文记忆模式。
- **可配置性**:
  - 通过UI界面和 `config.json` 文件管理外部工具（如 `llama.cpp`）的路径，增强了健壮性。

## 项目结构

- `main_app.py`: **(新)** 应用主入口，包含所有UI和业务逻辑。
- `train_core.py`: 核心训练逻辑。
- `inference_core.py`: 核心推理逻辑。
- `merge_and_import.py`: 模型合并、转换和导入的逻辑。
- `azure.tcl`, `config.json`: **(新)** UI主题和配置文件。
- `requirements.txt`: 项目 Python 依赖项。
- `shangganwenxue.jsonl`, `zhexuejia.jsonl`: 示例数据集。

## 安装与使用

### 1. 环境准备

(与之前相同)

### 2. 安装依赖

(与之前相同)

### 3. 配置 (重要)

首次运行前，请完成以下配置：

- **克隆 `llama.cpp`**: `merge_and_import.py` 依赖于 `llama.cpp` 仓库中的转换脚本。请将其克隆到您电脑的任意位置。
  ```bash
  git clone https://github.com/ggerganov/llama.cpp.git
  ```
- **运行应用并设置路径**: 
  1. 启动主程序：
     ```bash
     python main_app.py
     ```
  2. 切换到 **[设置 (Settings)]** 标签页。
  3. 点击“浏览...”按钮，选择您刚刚克隆的 `llama.cpp` 仓库的根目录。
  4. 点击“保存设置”。

### 4. 使用方法

- **训练**: 
  - 在 **[训练 (Train)]** 标签页中，选择训练模式（新训练或继续训练），选择模型和数据，然后点击“开始训练”。
- **管理与转换**:
  - 在 **[模型管理 (Manage)]** 标签页中，执行合并LoRA或转换基座模型的操作。
- **推理测试**:
  - 在 **[推理 (Inference)]** 标签页中，从下拉框选择任意一个可用模型，加载后即可开始对话。

## 示例数据格式

训练数据应为 JSONL 格式，每行一个 JSON 对象，包含 `instruction`, `input`, `output` 字段。例如：

```json
{"instruction": "把这句话变成押韵的问句。", "input": "猫咪在睡觉。", "output": "猫咪在睡觉，是否睡得香甜又美妙？"}
{"instruction": "请总结以下文章。", "input": "[文章内容]", "output": "[总结内容]"}
```

## 许可证

本项目采用 MIT 许可证。